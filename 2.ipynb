{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SPACE = 28\n",
    "ACTION_SPACE = 3\n",
    "\n",
    "ACTION_LOW = -1\n",
    "ACTION_HIGH = 1\n",
    "\n",
    "GAMMA = 0.9995\n",
    "TAU = 1e-3\n",
    "EPS_START = 1.0\n",
    "EPS_END = 0.1\n",
    "EPS_DECAY = 0.9\n",
    "\n",
    "MEMORY_LEN = 10000\n",
    "MEMORY_THRESH = 500\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "LR_DQN = 5e-4\n",
    "\n",
    "LEARN_AFTER = MEMORY_THRESH\n",
    "LEARN_EVERY = 3\n",
    "UPDATE_EVERY = 9\n",
    "\n",
    "COST = 3e-4\n",
    "CAPITAL = 100000\n",
    "NEG_MUL = 2\n",
    "\n",
    "DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class DataGetter:\n",
    "  \"\"\"\n",
    "  The class for getting data for assets.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, asset=\"BTC-USD\", start_date=None, end_date=None, freq=\"1d\", \n",
    "               timeframes=[1, 2, 5, 10, 20, 40]):\n",
    "    self.asset = asset\n",
    "    self.sd = start_date\n",
    "    self.ed = end_date\n",
    "    self.freq = freq\n",
    "\n",
    "    self.timeframes = timeframes\n",
    "    self.getData()\n",
    "\n",
    "    self.scaler = StandardScaler()\n",
    "    self.scaler.fit(self.data[:, 1:])\n",
    "\n",
    "\n",
    "  def getData(self):\n",
    "    \n",
    "    asset = self.asset  \n",
    "    if self.sd is not None and self.ed is not None:\n",
    "      df =  yf.download([asset], start=self.sd, end=self.ed, interval=self.freq)\n",
    "      df_spy = yf.download([\"BTC-USD\"], start=self.sd, end=self.ed, interval=self.freq)\n",
    "    elif self.sd is None and self.ed is not None:\n",
    "      df =  yf.download([asset], end=self.ed, interval=self.freq)\n",
    "      df_spy = yf.download([\"BTC-USD\"], end=self.ed, interval=self.freq)\n",
    "    elif self.sd is not None and self.ed is None:\n",
    "      df =  yf.download([asset], start=self.sd, interval=self.freq)\n",
    "      df_spy = yf.download([\"BTC-USD\"], start=self.sd, interval=self.freq)\n",
    "    else:\n",
    "      df = yf.download([asset], period=\"max\", interval=self.freq)\n",
    "      df_spy = yf.download([\"BTC-USD\"], interval=self.freq)\n",
    "    \n",
    "    # Reward - Not included in Observation Space.\n",
    "    df[\"rf\"] = df[\"Adj Close\"].pct_change().shift(-1)\n",
    "\n",
    "    # Returns and Trading Volume Changes\n",
    "    for i in self.timeframes:\n",
    "      df_spy[f\"spy_ret-{i}\"] = df_spy[\"Adj Close\"].pct_change(i)\n",
    "      df_spy[f\"spy_v-{i}\"] = df_spy[\"Volume\"].pct_change(i)\n",
    "\n",
    "      df[f\"r-{i}\"] = df[\"Adj Close\"].pct_change(i)      \n",
    "      df[f\"v-{i}\"] = df[\"Volume\"].pct_change(i)\n",
    "    \n",
    "    # Volatility\n",
    "    for i in [5, 10, 20, 40]:\n",
    "      df[f'sig-{i}'] = np.log(1 + df[\"r-1\"]).rolling(i).std()\n",
    "\n",
    "    # Moving Average Convergence Divergence (MACD)\n",
    "    df[\"macd_lmw\"] = df[\"r-1\"].ewm(span=26, adjust=False).mean()\n",
    "    df[\"macd_smw\"] = df[\"r-1\"].ewm(span=12, adjust=False).mean()\n",
    "    df[\"macd_bl\"] = df[\"r-1\"].ewm(span=9, adjust=False).mean()\n",
    "    df[\"macd\"] = df[\"macd_smw\"] - df[\"macd_lmw\"]\n",
    "\n",
    "    # Relative Strength Indicator (RSI)\n",
    "    rsi_lb = 5\n",
    "    pos_gain = df[\"r-1\"].where(df[\"r-1\"] > 0, 0).ewm(rsi_lb).mean()\n",
    "    neg_gain = df[\"r-1\"].where(df[\"r-1\"] < 0, 0).ewm(rsi_lb).mean()\n",
    "    rs = np.abs(pos_gain/neg_gain)\n",
    "    df[\"rsi\"] = 100 * rs/(1 + rs)\n",
    "\n",
    "    # Bollinger Bands\n",
    "    bollinger_lback = 10\n",
    "    df[\"bollinger\"] = df[\"r-1\"].ewm(bollinger_lback).mean()\n",
    "    df[\"low_bollinger\"] = df[\"bollinger\"] - 2 * df[\"r-1\"].rolling(bollinger_lback).std()\n",
    "    df[\"high_bollinger\"] = df[\"bollinger\"] + 2 * df[\"r-1\"].rolling(bollinger_lback).std()\n",
    "\n",
    "    # SP500\n",
    "    #df = df.merge(df_spy[[f\"spy_ret-{i}\" for i in self.timeframes] + [f\"spy_sig-{i}\" for i in [5, 10, 20, 40]]], \n",
    "    #              how=\"left\", right_index=True, left_index=True)\n",
    "\n",
    "    # Filtering\n",
    "    for c in df.columns:\n",
    "      df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    self.frame = df\n",
    "    self.data = np.array(df.iloc[:, 6:])\n",
    "    return\n",
    "\n",
    "\n",
    "  def scaleData(self):\n",
    "    self.scaled_data = self.scaler.fit_transform(self.data[:, 1:])\n",
    "    return\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "\n",
    "  def __getitem__(self, idx, col_idx=None):\n",
    "    if col_idx is None:\n",
    "      return self.data[idx]\n",
    "    elif col_idx < len(list(self.data.columns)):\n",
    "      return self.data[idx][col_idx]\n",
    "    else:\n",
    "      raise IndexError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAssetTradingEnvironment:\n",
    "  \"\"\"\n",
    "  Trading Environment for trading a single asset.\n",
    "  The Agent interacts with the environment class through the step() function.\n",
    "  Action Space: {-1: Sell, 0: Do Nothing, 1: Buy}\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, asset_data,\n",
    "               initial_money=CAPITAL, trans_cost=COST, store_flag=1, asset_ph=0, \n",
    "               capital_frac=0.2, running_thresh=0.1, cap_thresh=0.3):\n",
    "\n",
    "    self.past_holding = asset_ph\n",
    "    self.capital_frac = capital_frac # Fraction of capital to invest each time.\n",
    "    self.cap_thresh = cap_thresh\n",
    "    self.running_thresh = running_thresh\n",
    "    self.trans_cost = trans_cost\n",
    "\n",
    "    self.asset_data = asset_data\n",
    "    self.terminal_idx = len(self.asset_data) - 1\n",
    "    self.scaler = self.asset_data.scaler    \n",
    "\n",
    "    self.initial_cap = initial_money\n",
    "\n",
    "    self.capital = self.initial_cap\n",
    "    self.running_capital = self.capital\n",
    "    self.asset_inv = self.past_holding\n",
    "\n",
    "    self.pointer = 0\n",
    "    self.next_return, self.current_state = 0, None\n",
    "    self.prev_act = 0\n",
    "    self.current_act = 0\n",
    "    self.current_reward = 0\n",
    "    self.current_price = self.asset_data.frame.iloc[self.pointer, :]['Adj Close']\n",
    "    self.done = False\n",
    "\n",
    "    self.store_flag = store_flag\n",
    "    if self.store_flag == 1:\n",
    "      self.store = {\"action_store\": [],\n",
    "                    \"reward_store\": [],\n",
    "                    \"running_capital\": [],\n",
    "                    \"port_ret\": []}\n",
    "\n",
    "\n",
    "  def reset(self):\n",
    "    self.capital = self.initial_cap\n",
    "    self.running_capital = self.capital\n",
    "    self.asset_inv = self.past_holding\n",
    "\n",
    "    self.pointer = 0\n",
    "    self.next_return, self.current_state = self.get_state(self.pointer)\n",
    "    self.prev_act = 0\n",
    "    self.current_act = 0\n",
    "    self.current_reward = 0\n",
    "    self.current_price = self.asset_data.frame.iloc[self.pointer, :]['Adj Close']\n",
    "    self.done = False\n",
    "    \n",
    "    if self.store_flag == 1:\n",
    "      self.store = {\"action_store\": [],\n",
    "                    \"reward_store\": [],\n",
    "                    \"running_capital\": [],\n",
    "                    \"port_ret\": []}\n",
    "\n",
    "    return self.current_state\n",
    "\n",
    "\n",
    "  def step(self, action):\n",
    "    self.current_act = action\n",
    "    self.current_price = self.asset_data.frame.iloc[self.pointer, :]['Adj Close']\n",
    "    self.current_reward = self.calculate_reward()\n",
    "    self.prev_act = self.current_act\n",
    "    self.pointer += 1\n",
    "    self.next_return, self.current_state = self.get_state(self.pointer)\n",
    "    self.done = self.check_terminal()\n",
    "\n",
    "    if self.done:\n",
    "      reward_offset = 0\n",
    "      ret = (self.store['running_capital'][-1]/self.store['running_capital'][-0]) - 1\n",
    "      if self.pointer < self.terminal_idx:\n",
    "        reward_offset += -1 * max(0.5, 1 - self.pointer/self.terminal_idx)\n",
    "      if self.store_flag:\n",
    "        reward_offset += 10 * ret\n",
    "      self.current_reward += reward_offset\n",
    "\n",
    "    if self.store_flag:\n",
    "      self.store[\"action_store\"].append(self.current_act)\n",
    "      self.store[\"reward_store\"].append(self.current_reward)\n",
    "      self.store[\"running_capital\"].append(self.capital)\n",
    "      info = self.store\n",
    "    else:\n",
    "      info = None\n",
    "    \n",
    "    return self.current_state, self.current_reward, self.done, info\n",
    "\n",
    "\n",
    "  def calculate_reward(self):\n",
    "    investment = self.running_capital * self.capital_frac\n",
    "    reward_offset = 0\n",
    "\n",
    "    # Buy Action\n",
    "    if self.current_act == 1: \n",
    "      if self.running_capital > self.initial_cap * self.running_thresh:\n",
    "        self.running_capital -= investment\n",
    "        asset_units = investment/self.current_price\n",
    "        self.asset_inv += asset_units\n",
    "        self.current_price *= (1 - self.trans_cost)\n",
    "\n",
    "    # Sell Action\n",
    "    elif self.current_act == -1:\n",
    "      if self.asset_inv > 0:\n",
    "        self.running_capital += self.asset_inv * self.current_price * (1 - self.trans_cost)\n",
    "        self.asset_inv = 0\n",
    "\n",
    "    # Do Nothing\n",
    "    elif self.current_act == 0:\n",
    "      if self.prev_act == 0:\n",
    "        reward_offset += -0.1\n",
    "      pass\n",
    "    \n",
    "    # Reward to give\n",
    "    prev_cap = self.capital\n",
    "    self.capital = self.running_capital + (self.asset_inv) * self.current_price\n",
    "    reward = 100*(self.next_return) * self.current_act - np.abs(self.current_act - self.prev_act) * self.trans_cost\n",
    "    if self.store_flag==1:\n",
    "      self.store['port_ret'].append((self.capital - prev_cap)/prev_cap)\n",
    "    \n",
    "    if reward < 0:\n",
    "      reward *= NEG_MUL  # To make the Agent more risk averse towards negative returns.\n",
    "    reward += reward_offset\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "  def check_terminal(self):\n",
    "    if self.pointer == self.terminal_idx:\n",
    "      return True\n",
    "    elif self.capital <= self.initial_cap * self.cap_thresh:\n",
    "      return True\n",
    "    else:\n",
    "      return False\n",
    "\n",
    "\n",
    "  def get_state(self, idx):\n",
    "    state = self.asset_data[idx][1:]\n",
    "    state = self.scaler.transform(state.reshape(1, -1))\n",
    "\n",
    "    state = np.concatenate([state, [[self.capital/self.initial_cap,\n",
    "                                     self.running_capital/self.capital,\n",
    "                                     self.asset_inv * self.current_price/self.initial_cap,\n",
    "                                     self.prev_act]]], axis=-1)\n",
    "    \n",
    "    next_ret = self.asset_data[idx][0]\n",
    "    return next_ret, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Transition = namedtuple(\"Transition\", [\"States\", \"Actions\", \"Rewards\", \"NextStates\", \"Dones\"])\n",
    "\n",
    "\n",
    "class ReplayMemory:\n",
    "  \"\"\"\n",
    "  Implementation of Agent memory\n",
    "  \"\"\"\n",
    "  def __init__(self, capacity=MEMORY_LEN):\n",
    "    self.memory = deque(maxlen=capacity)\n",
    "\n",
    "  def store(self, t):\n",
    "    self.memory.append(t)\n",
    "\n",
    "  def sample(self, n):\n",
    "    a = random.sample(self.memory, n)\n",
    "    return a\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "class DuellingDQN(nn.Module):\n",
    "  \"\"\"\n",
    "  Acrchitecture for Duelling Deep Q Network Agent\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, input_dim=STATE_SPACE, output_dim=ACTION_SPACE):\n",
    "    super(DuellingDQN, self).__init__()\n",
    "    self.input_dim = input_dim\n",
    "    self.output_dim = output_dim\n",
    "\n",
    "    self.fc1 = nn.Linear(self.input_dim, 500)\n",
    "    self.fc2 = nn.Linear(500, 500)\n",
    "    self.fc3 = nn.Linear(500, 300)\n",
    "    self.fc4 = nn.Linear(300, 200)\n",
    "    self.fc5 = nn.Linear(200, 10)\n",
    "\n",
    "    self.fcs = nn.Linear(10, 1)\n",
    "    self.fcp = nn.Linear(10, self.output_dim)\n",
    "    self.fco = nn.Linear(self.output_dim + 1, self.output_dim)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "    self.tanh = nn.Tanh()\n",
    "    self.sig = nn.Sigmoid()\n",
    "    self.sm = nn.Softmax(dim=1)\n",
    "\n",
    "  def forward(self, state):\n",
    "    x = self.relu(self.fc1(state))\n",
    "    x = self.relu(self.fc2(x))\n",
    "    x = self.relu(self.fc3(x))\n",
    "    x = self.relu(self.fc4(x))\n",
    "    x = self.relu(self.fc5(x))\n",
    "    xs = self.relu(self.fcs(x))\n",
    "    xp = self.relu(self.fcp(x))\n",
    "\n",
    "    x = xs + xp - xp.mean()\n",
    "    return x\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "  \"\"\"\n",
    "  Implements the Agent components\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, actor_net=DuellingDQN, memory=ReplayMemory()):\n",
    "    \n",
    "    self.actor_online = actor_net(STATE_SPACE, ACTION_SPACE).to(DEVICE)\n",
    "    self.actor_target = actor_net(STATE_SPACE, ACTION_SPACE).to(DEVICE)\n",
    "    self.actor_target.load_state_dict(self.actor_online.state_dict())\n",
    "    self.actor_target.eval()\n",
    "\n",
    "    self.memory = memory\n",
    "\n",
    "    self.actor_criterion = nn.MSELoss()\n",
    "    self.actor_op = optim.Adam(self.actor_online.parameters(), lr=LR_DQN)\n",
    "\n",
    "    self.t_step = 0\n",
    "\n",
    "\n",
    "  def act(self, state, eps=0.):\n",
    "    self.t_step += 1\n",
    "    state = torch.from_numpy(state).float().to(DEVICE).view(1, -1)\n",
    "    \n",
    "    self.actor_online.eval()\n",
    "    with torch.no_grad():\n",
    "      actions = self.actor_online(state)\n",
    "    self.actor_online.train()\n",
    "\n",
    "    if random.random() > eps:\n",
    "      act = np.argmax(actions.cpu().data.numpy())\n",
    "    else:\n",
    "      act = random.choice(np.arange(ACTION_SPACE))\n",
    "    return int(act)\n",
    "\n",
    "\n",
    "  def learn(self):\n",
    "    if len(self.memory) <= MEMORY_THRESH:\n",
    "      return 0\n",
    "\n",
    "    if self.t_step > LEARN_AFTER and self.t_step % LEARN_EVERY==0:\n",
    "    # Sample experiences from the Memory\n",
    "      batch = self.memory.sample(BATCH_SIZE)\n",
    "\n",
    "      states = np.vstack([t.States for t in batch])\n",
    "      states = torch.from_numpy(states).float().to(DEVICE)\n",
    "\n",
    "      actions = np.vstack([t.Actions for t in batch])\n",
    "      actions = torch.from_numpy(actions).float().to(DEVICE)\n",
    "\n",
    "      rewards = np.vstack([t.Rewards for t in batch])\n",
    "      rewards = torch.from_numpy(rewards).float().to(DEVICE)\n",
    "\n",
    "      next_states = np.vstack([t.NextStates for t in batch])\n",
    "      next_states = torch.from_numpy(next_states).float().to(DEVICE)\n",
    "\n",
    "      dones = np.vstack([t.Dones for t in batch]).astype(np.uint8)\n",
    "      dones = torch.from_numpy(dones).float().to(DEVICE)\n",
    "\n",
    "      # ACTOR UPDATE\n",
    "      # Compute next state actions and state values\n",
    "      next_state_values = self.actor_target(next_states).max(1)[0].unsqueeze(1)\n",
    "      y = rewards + (1-dones) * GAMMA * next_state_values\n",
    "      state_values = self.actor_online(states).gather(1, actions.type(torch.int64))\n",
    "      # Compute Actor loss\n",
    "      actor_loss = self.actor_criterion(y, state_values)\n",
    "      # Minimize Actor loss\n",
    "      self.actor_op.zero_grad()\n",
    "      actor_loss.backward()\n",
    "      self.actor_op.step()\n",
    "\n",
    "      if self.t_step % UPDATE_EVERY == 0:\n",
    "        self.soft_update(self.actor_online, self.actor_target)\n",
    "      # return actor_loss.item()\n",
    "\n",
    "\n",
    "  def soft_update(self, local_model, target_model, tau=TAU):\n",
    "    for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "      target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "/tmp/ipykernel_20166/2205038994.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[c].interpolate('linear', limit_direction='both', inplace=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m t \u001b[38;5;241m=\u001b[39m Transition(state, actions, reward, next_state, done)\n\u001b[1;32m     43\u001b[0m agent\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mstore(t)\n\u001b[0;32m---> 44\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m     47\u001b[0m score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[0;32mIn[7], line 108\u001b[0m, in \u001b[0;36mDQNAgent.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m next_state_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_target(next_states)\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    107\u001b[0m y \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mdones) \u001b[38;5;241m*\u001b[39m GAMMA \u001b[38;5;241m*\u001b[39m next_state_values\n\u001b[0;32m--> 108\u001b[0m state_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor_online\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, actions\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mint64))\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Compute Actor loss\u001b[39;00m\n\u001b[1;32m    110\u001b[0m actor_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_criterion(y, state_values)\n",
      "File \u001b[0;32m~/Documents/UE1bis_reinforcement_learning/rl_project/rlenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UE1bis_reinforcement_learning/rl_project/rlenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 35\u001b[0m, in \u001b[0;36mDuellingDQN.forward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(state))\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m---> 35\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc4(x))\n\u001b[1;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc5(x))\n",
      "File \u001b[0;32m~/Documents/UE1bis_reinforcement_learning/rl_project/rlenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UE1bis_reinforcement_learning/rl_project/rlenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UE1bis_reinforcement_learning/rl_project/rlenv/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Environment and Agent Initiation\n",
    "\n",
    "## Cryptocurrency Tickers\n",
    "asset_codes = [\"ETH-USD\", \"BNB-USD\", \"XRP-USD\", \"SOL-USD\", \"DOGE-USD\", \n",
    "               \"ADA-USD\", \"MATIC-USD\", \"AVAX-USD\", \"WAVES-USD\"]\n",
    "\n",
    "## Training and Testing Environments\n",
    "assets = [DataGetter(a, start_date=\"2015-01-01\", end_date=\"2021-05-01\") for a in asset_codes]\n",
    "test_assets = [DataGetter(a, start_date=\"2021-05-01\", end_date=\"2022-05-01\", freq=\"1d\") for a in asset_codes]\n",
    "envs = [SingleAssetTradingEnvironment(a) for a in assets]\n",
    "test_envs = [SingleAssetTradingEnvironment(a) for a in test_assets]\n",
    "\n",
    "## Agent\n",
    "memory = ReplayMemory()\n",
    "agent = DQNAgent(actor_net=DuellingDQN, memory=memory)\n",
    "\n",
    "# Main training loop\n",
    "N_EPISODES = 20 # No of episodes/epochs\n",
    "scores = []\n",
    "eps = EPS_START\n",
    "act_dict = {0:-1, 1:1, 2:0}\n",
    "\n",
    "te_score_min = -np.Inf\n",
    "for episode in range(1, 1 + N_EPISODES):\n",
    "  counter = 0\n",
    "  episode_score = 0\n",
    "  episode_score2 = 0\n",
    "  test_score = 0\n",
    "  test_score2 = 0\n",
    "\n",
    "  for env in envs:\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    state = state.reshape(-1, STATE_SPACE)\n",
    "    while True:\n",
    "      actions = agent.act(state, eps)\n",
    "      action = act_dict[actions]\n",
    "      next_state, reward, done, _ = env.step(action)\n",
    "      next_state = next_state.reshape(-1, STATE_SPACE)\n",
    "\n",
    "      t = Transition(state, actions, reward, next_state, done)\n",
    "      agent.memory.store(t)\n",
    "      agent.learn()\n",
    "\n",
    "      state = next_state\n",
    "      score += reward\n",
    "      counter += 1\n",
    "      if done:\n",
    "        break\n",
    "\n",
    "    episode_score += score\n",
    "    episode_score2 += (env.store['running_capital'][-1] - env.store['running_capital'][0])\n",
    "\n",
    "  scores.append(episode_score)\n",
    "  eps = max(EPS_END, EPS_DECAY * eps)\n",
    "\n",
    "  for i, test_env in enumerate(test_envs):\n",
    "    state = test_env.reset()\n",
    "    done = False\n",
    "    score_te = 0\n",
    "    scores_te = [score_te]\n",
    "\n",
    "    while True:\n",
    "      actions = agent.act(state)\n",
    "      action = act_dict[actions]\n",
    "      next_state, reward, done, _ = test_env.step(action)\n",
    "      next_state = next_state.reshape(-1, STATE_SPACE)\n",
    "      state= next_state\n",
    "      score_te += reward\n",
    "      scores_te.append(score_te)\n",
    "      if done:\n",
    "        break\n",
    "\n",
    "    test_score += score_te\n",
    "    test_score2 += (test_env.store['running_capital'][-1] - test_env.store['running_capital'][0])\n",
    "  if test_score > te_score_min:\n",
    "    te_score_min = test_score\n",
    "    torch.save(agent.actor_online.state_dict(), \"online.pt\")\n",
    "    torch.save(agent.actor_target.state_dict(), \"target.pt\")\n",
    "\n",
    "  print(f\"Episode: {episode}, Train Score: {episode_score:.5f}, Validation Score: {test_score:.5f}\")\n",
    "  print(f\"Episode: {episode}, Train Value: ${episode_score2:.5f}, Validation Value: ${test_score2:.5f}\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "1\n",
      "1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "------\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "99994.0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "------\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "99842.6528144589\n",
      "1\n",
      "1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "------\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "97397.58535804055\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "1\n",
      "0\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "------\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "99802.21753522391\n",
      "1\n",
      "1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "-1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "1\n",
      "------\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "97033.8428851215\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "-1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "------\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "93807.97269516313\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "------\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "94692.81462725121\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "-1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "------\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "95606.30284303176\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "-1\n",
      "1\n",
      "0\n",
      "-1\n",
      "0\n",
      "1\n",
      "0\n",
      "-1\n",
      "0\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "-1\n",
      "-1\n",
      "0\n",
      "------\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n",
      "100000.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Environment and Agent Initiation\n",
    "\n",
    "## Cryptocurrency Tickers\n",
    "asset_codes = [\"ETH-USD\", \"BNB-USD\", \"XRP-USD\", \"SOL-USD\", \"DOGE-USD\", \n",
    "               \"ADA-USD\", \"MATIC-USD\", \"AVAX-USD\", \"WAVES-USD\"]\n",
    "\n",
    "test_assets = [DataGetter(a, start_date=\"2024-01-01\", end_date=\"2024-03-01\", freq=\"1d\") for a in asset_codes]\n",
    "test_envs = [SingleAssetTradingEnvironment(a) for a in test_assets]\n",
    "\n",
    "## Agent\n",
    "#memory = ReplayMemory()\n",
    "#agent = DQNAgent(actor_net=DuellingDQN, memory=memory)\n",
    "\n",
    "\n",
    "act_dict = {0:-1, 1:1, 2:0}\n",
    "\n",
    "te_score_min = -np.Inf\n",
    "\n",
    "\n",
    "\n",
    "counter = 0\n",
    "episode_score = 0\n",
    "episode_score2 = 0\n",
    "test_score = 0\n",
    "test_score2 = 0\n",
    "\n",
    "\n",
    "for i, test_env in enumerate(test_envs):\n",
    "  state = test_env.reset()\n",
    "  done = False\n",
    "  score_te = 0\n",
    "  scores_te = [score_te]\n",
    "\n",
    "  while True:\n",
    "\n",
    "    actions = agent.act(state)\n",
    "    action = act_dict[actions]\n",
    "    print(action)\n",
    "    next_state, reward, done, _ = test_env.step(action)\n",
    "    next_state = next_state.reshape(-1, STATE_SPACE)\n",
    "    state= next_state\n",
    "    score_te += reward\n",
    "    scores_te.append(score_te)\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "  test_score += score_te\n",
    "  test_score2 += (test_env.store['running_capital'][-1] - test_env.store['running_capital'][0])\n",
    "\n",
    "  print('------')\n",
    "  for c in test_env.store['running_capital']:\n",
    "    print(test_env.store['running_capital'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_assets[0].data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
