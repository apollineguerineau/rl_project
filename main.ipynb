{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading agent demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from modules.data_loader import DataLoader\n",
    "from modules.single_asset_env import SingleAssetEnv\n",
    "from modules.q_network import Q_network\n",
    "from modules.memory import Memory\n",
    "from modules.trading_agent import TradingAgent\n",
    "from modules.functions import train_agent, test_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = int(os.environ[\"NUM_ACTIONS\"])\n",
    "states_dim = int(os.environ[\"STATES_DIM\"])\n",
    "\n",
    "num_epochs = int(os.environ[\"NUM_EPOCHS\"])\n",
    "batch_size = int(os.environ[\"BATCH_SIZE\"])\n",
    "memory_size = int(os.environ[\"MEMORY_SIZE\"])\n",
    "\n",
    "learning_rate = float(os.environ[\"LEARNING_RATE\"])\n",
    "learning_freq = int(os.environ[\"LEARNING_FREQ\"])\n",
    "\n",
    "tau = float(os.environ[\"TAU\"])\n",
    "gamma = float(os.environ[\"GAMMA\"])\n",
    "\n",
    "device = os.environ[\"DEVICE\"]\n",
    "seed = int(os.environ[\"SEED\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(os.environ[\"START_DATE\"], \n",
    "                        os.environ[\"FREQ\"],\n",
    "                        os.environ[\"TRAIN_TEST_SPLIT_DATE\"])\n",
    "\n",
    "assets = json.loads(os.environ[\"ASSETS\"])\n",
    "\n",
    "trains = []\n",
    "tests = []\n",
    "\n",
    "for asset in assets:\n",
    "    train, test = dataloader.load(asset)\n",
    "\n",
    "    trains.append(train)\n",
    "    tests.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_envs = [SingleAssetEnv(train) for train in trains]\n",
    "\n",
    "agent = TradingAgent(states_dim, num_actions, assets, \n",
    "                     batch_size=batch_size,\n",
    "                     memory_size=memory_size,\n",
    "                     learning_rate=learning_rate,\n",
    "                     tau=tau,\n",
    "                     gamma=gamma,\n",
    "                     learning_freq=learning_freq,\n",
    "                     device=device,\n",
    "                     seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 | Scores = {'BTC-USD': 296572278.3125, 'ETH-USD': 9544927.971069336, 'BNB-USD': 25288523.3691473}\n",
      "Epoch  1 | Scores = {'BTC-USD': 99544648.1171875, 'ETH-USD': 39672303.16938019, 'BNB-USD': 52754580.03080559}\n",
      "Epoch  2 | Scores = {'BTC-USD': 20834248.239257812, 'ETH-USD': 509770981.7358246, 'BNB-USD': 52754580.03080559}\n",
      "Epoch  3 | Scores = {'BTC-USD': 48416802.56982422, 'ETH-USD': 509770981.7358246, 'BNB-USD': 52754580.03080559}\n",
      "Epoch  4 | Scores = {'BTC-USD': 51727365.248535156, 'ETH-USD': 509870881.7358246, 'BNB-USD': 52700064.767388344}\n",
      "Epoch  5 | Scores = {'BTC-USD': 3305325.9467773438, 'ETH-USD': 310621897.19981384, 'BNB-USD': 52754580.03080559}\n",
      "Epoch  6 | Scores = {'BTC-USD': -787057.7978515625, 'ETH-USD': 386887130.8197479, 'BNB-USD': 136349080.0138378}\n",
      "Epoch  7 | Scores = {'BTC-USD': 3156708.560546875, 'ETH-USD': 438878158.89445496, 'BNB-USD': 52754580.03080559}\n",
      "Epoch  8 | Scores = {'BTC-USD': 54870199.69580078, 'ETH-USD': 509870881.7358246, 'BNB-USD': 52754580.03080559}\n",
      "Epoch  9 | Scores = {'BTC-USD': 276248775.0419922, 'ETH-USD': 841978876.8782196, 'BNB-USD': 53071251.96677971}\n",
      "Epoch 10 | Scores = {'BTC-USD': 4325903.91015625, 'ETH-USD': 509770981.7358246, 'BNB-USD': 52854480.03080559}\n",
      "Epoch 11 | Scores = {'BTC-USD': 125242207.3725586, 'ETH-USD': 507965149.18714905, 'BNB-USD': 52754580.03080559}\n",
      "Epoch 12 | Scores = {'BTC-USD': 1090426.4340820312, 'ETH-USD': 503897194.12498474, 'BNB-USD': 52618396.63427544}\n",
      "Epoch 13 | Scores = {'BTC-USD': 16782127.420898438, 'ETH-USD': 509698705.9618988, 'BNB-USD': 52754580.03080559}\n",
      "Epoch 14 | Scores = {'BTC-USD': 132582059.75732422, 'ETH-USD': 509770981.7358246, 'BNB-USD': 52594080.71886158}\n",
      "Epoch 15 | Scores = {'BTC-USD': 275285593.140625, 'ETH-USD': 509770981.7358246, 'BNB-USD': 52754580.03080559}\n",
      "Epoch 16 | Scores = {'BTC-USD': -257577.6513671875, 'ETH-USD': 509870881.7358246, 'BNB-USD': 71996941.24027824}\n",
      "Epoch 17 | Scores = {'BTC-USD': 251937761.03808594, 'ETH-USD': 507875768.76862335, 'BNB-USD': -121700.0}\n",
      "Epoch 18 | Scores = {'BTC-USD': 58576461.666015625, 'ETH-USD': 684157349.9365311, 'BNB-USD': -121700.0}\n",
      "Epoch 19 | Scores = {'BTC-USD': -21612045.302734375, 'ETH-USD': 216362271.80768585, 'BNB-USD': 163382.34287071228}\n",
      "Epoch 20 | Scores = {'BTC-USD': 271454750.7705078, 'ETH-USD': 507775868.76862335, 'BNB-USD': 196579.16934776306}\n",
      "Epoch 21 | Scores = {'BTC-USD': 4532617.267578125, 'ETH-USD': 345595256.08911896, 'BNB-USD': 163382.34287071228}\n",
      "Epoch 22 | Scores = {'BTC-USD': 176938428.00097656, 'ETH-USD': 507875768.76862335, 'BNB-USD': 163382.34287071228}\n",
      "Epoch 23 | Scores = {'BTC-USD': 31753159.33642578, 'ETH-USD': 507875768.76862335, 'BNB-USD': 163382.34287071228}\n",
      "Epoch 24 | Scores = {'BTC-USD': 12100539.857421875, 'ETH-USD': 507875768.76862335, 'BNB-USD': 37171009.166223526}\n",
      "Epoch 25 | Scores = {'BTC-USD': 301482990.6328125, 'ETH-USD': 169001862.7105484, 'BNB-USD': -121700.0}\n",
      "Epoch 26 | Scores = {'BTC-USD': 57461673.99121094, 'ETH-USD': 507875768.76862335, 'BNB-USD': -121700.0}\n",
      "Epoch 27 | Scores = {'BTC-USD': 86045081.72802734, 'ETH-USD': 558025568.7686234, 'BNB-USD': -121700.0}\n",
      "Epoch 28 | Scores = {'BTC-USD': 138232477.37548828, 'ETH-USD': 5181109.990539551, 'BNB-USD': -121700.0}\n",
      "Epoch 29 | Scores = {'BTC-USD': 25674898.97607422, 'ETH-USD': 289122645.1332092, 'BNB-USD': -121700.0}\n",
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "train_agent(assets, agent, train_envs, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial capital : 100000$ for each asset\n",
      "\n",
      "Balance : BTC-USD: 100000.0\n",
      "Balance : ETH-USD: 228668.56311035156\n",
      "Balance : BNB-USD: 102471.3832397461\n",
      "---------------------------\n",
      "Total profit made: 131139.94635009766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'BTC-USD': 100000.0,\n",
       " 'ETH-USD': 228668.56311035156,\n",
       " 'BNB-USD': 102471.3832397461}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_envs = [SingleAssetEnv(test) for test in tests]\n",
    "\n",
    "print('Initial capital : 100000$ for each asset\\n')\n",
    "\n",
    "test_agent(assets, test_envs, agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To test app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance : BTC-USD: 100000.0\n",
      "Balance : ETH-USD: 228668.56311035156\n",
      "Balance : BNB-USD: 102471.3832397461\n",
      "---------------------------\n",
      "Total profit made: 131139.94635009766\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from modules.data_loader import DataLoader\n",
    "def test_agent(assets, test_envs, agent):\n",
    "    total_profit = 0\n",
    "    final_running_balance_dict = {}\n",
    "    for asset, env in zip(assets, test_envs):\n",
    "\n",
    "        state = env.reset()\n",
    "\n",
    "        test_actions = []\n",
    "        test_rewards = []\n",
    "\n",
    "        for _ in range(len(env.data)-1):\n",
    "            \n",
    "            action = agent.qnets[agent.map_assets[asset]](torch.from_numpy(np.array(state, dtype=np.float32).reshape(1, -1)))\n",
    "            action = np.argmax(action.data)\n",
    "\n",
    "            test_actions.append(action.item())\n",
    "                    \n",
    "            next_state, reward, done = env.step(action.numpy())\n",
    "            test_rewards.append(reward)\n",
    "\n",
    "            state = next_state\n",
    "    \n",
    "        final_running_balance = (env.data.iloc[env.t]['Close']*env.positions) + env.balance\n",
    "        final_running_balance_dict[asset] = final_running_balance\n",
    "        total_profit += (env.data.iloc[env.t]['Close']*env.positions) + env.balance - env.initial_balance\n",
    "        print(f\"Balance : {asset}: {final_running_balance}\")\n",
    "\n",
    "    print(\"-\"*27)\n",
    "    print(f\"Total profit made: {total_profit}\")\n",
    "\n",
    "    return final_running_balance_dict\n",
    "\n",
    "def train_agent(assets, train_envs, agent, NUM_EPOCHS):\n",
    "    scores = {key: [] for key in assets}\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        # intialise score for the epoch\n",
    "        score = {key: 0 for key in assets}\n",
    "        step_count = 1\n",
    "\n",
    "        for asset, env in zip(assets, train_envs):\n",
    "\n",
    "            # reset the environment before each epoch + get initial state\n",
    "            state = env.reset()\n",
    "\n",
    "            while True:\n",
    "\n",
    "                # find epsilon greedy action from state\n",
    "                action = agent.act(asset, state, 1/step_count) # epsilon = 1/t\n",
    "\n",
    "                # perform step in the environment and get completing info\n",
    "                next_state, reward, done = env.step(action)\n",
    "\n",
    "                agent.step(asset, state, action, reward, next_state, done)\n",
    "\n",
    "                # prepare for next iteration\n",
    "                step_count += 1\n",
    "                state = next_state\n",
    "\n",
    "                score[asset] += reward\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "        # compute info about the epoch\n",
    "        for key in scores.keys():\n",
    "            scores[key].append(score[key])\n",
    "\n",
    "        print(f\"Epoch {epoch:2} | Scores = {score}\")\n",
    "\n",
    "    print(\"Training done!\")\n",
    "\n",
    "    # save Q_network model weights\n",
    "    agent.save_models(\"weights\")\n",
    "\n",
    "\n",
    "asset_name_test = \"BTC-USD\"\n",
    "model_path = \"weights/trained_agent_model_\"+asset_name_test+\".pth\"\n",
    "assets = [\"BTC-USD\", \"ETH-USD\", \"BNB-USD\"]\n",
    "\n",
    "## Load Training and Testing Dataset\n",
    "date_split = '2023-01-01'\n",
    "start_date = '2020-01-01'\n",
    "dataloader = DataLoader(start_date, '1d', date_split)\n",
    "\n",
    "\n",
    "trains = []\n",
    "tests = []\n",
    "\n",
    "for asset in assets:\n",
    "    train, test = dataloader.load(asset)\n",
    "\n",
    "    trains.append(train)\n",
    "    tests.append(test)\n",
    "\n",
    "# Environment and Agent Initiation\n",
    "train_envs = [SingleAssetEnv(train) for train in trains]\n",
    "test_envs = [SingleAssetEnv(test) for test in tests]\n",
    "agent = TradingAgent(states_dim, num_actions, assets, seed=seed)\n",
    "\n",
    "if os.path.exists(model_path) :\n",
    "    ## Agent\n",
    "    model_path = \"weights/trained_agent_model_\"+asset_name_test+\".pth\"\n",
    "    # Load the state dict\n",
    "    state_dict = torch.load(model_path)\n",
    "\n",
    "    # Set the loaded state dict to the Q network of the corresponding asset\n",
    "    agent.qnets[agent.map_assets[asset]].load_state_dict(state_dict)\n",
    "\n",
    "    final_running_balance_dict = test_agent(assets, test_envs, agent)\n",
    "\n",
    "else:  # TRAINING MODEL IN CASE IT IS NOT TRAINED YET\n",
    "    agent = TradingAgent(states_dim, num_actions, assets, seed=seed)    \n",
    "    train_agent(assets, train_envs, agent, num_epochs)\n",
    "    final_running_balance_dict = test_agent(assets, test_envs, agent)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c0acf22ca7497d002e5e6e252fe169a1f9bf4afdf57db37b4725403d5188d16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
